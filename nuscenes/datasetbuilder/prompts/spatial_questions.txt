SPATIAL CATEGORY: {spatial_category}

CATEGORY-SPECIFIC INSTRUCTIONS: {category_instructions}

GENERAL GUIDELINES:
1. Anchor the Question: Every question must revolve around the SOURCE OBJECT as the primary point of reference or the starting point of the spatial relation and the TARGET OBJECTS as the point of reference for the correct options.
2. Grounded Descriptions: Do not use bare labels like "the car." Use the full description provided, including appearance and activity (e.g., "the SUV (silver, parked on the curb with hazard lights on)").
3. Incorporate Activity: Use the activity/behavior of the objects (e.g., "waiting," "merging," "accelerating") to distinguish between multiple objects of the same class.
4. Logical Distractors: Ensure distractors are spatially plausible based on the scene but factually incorrect according to the provided SPATIAL CONTEXT and the other relationships.
5. Output Format: Return ONLY a JSON object with the fields: question, options, correct_option, and rationale.
6. Look at the other relationships to generate relevant question options so that the question has only one correct option.
7. The correct option must only have the source object or target object or its spatial context with respect to each other.
8. The distractors must be spatially plausible based on the scene but factually incorrect according to the provided SPATIAL CONTEXT and the other relationships.

REFINED IN-CONTEXT EXAMPLES:

Example 1 (Source-to-Target Directional / Egocentric):
{
  "question": "From the perspective of the sedan (white, stopped at a red light), in which direction is the pedestrian (wearing a yellow raincoat, stepping off the curb) located?",
  "options": {
    "A": "Directly behind the sedan",
    "B": "To the front-right of the sedan",
    "C": "To the front-left of the sedan",
    "D": "Parallel to the driver's side door"
  },
  "correct_option": "B",
  "rationale": "The spatial context places the pedestrian at a 45-degree angle relative to the sedan's forward heading, which corresponds to the front-right position."
}

Example 2 (Source-to-Multiple Targets / Proximity / Multi-hop):
{
  "question": "Which target is positioned closer to the cyclist pedaling in the bike lane along it's current path?",
  "options": {
    "A": "The delivery truck (brown, double-parked)",
    "B": "The mailbox (blue, near the street corner)",
    "C": "Both are at an equal distance",
    "D": "The cyclist has already passed both objects"
  },
  "correct_option": "A",
  "rationale": "The delivery truck is located 3m from the cyclist, whereas the mailbox is 8m away, making the truck the closer target."
}

Example 3 (Allocentric / Global Frame of Reference):
{
  "question": "Regarding the global scene layout, what is the spatial relationship between the red pickup truck traveling East through the intersection and the silver SUV parked by the sidewalk?",
  "options": {
    "A": "The pickup truck is South of the SUV's position",
    "B": "The pickup truck is North of the SUV's position",
    "C": "The pickup truck is West of the SUV's position",
    "D": "The pickup truck is parked directly behind the SUV"
  },
  "correct_option": "B",
  "rationale": "In the allocentric frame of the map, the pickup truck is located within the intersection which lies to the North of the stationary SUV's coordinates."
}

INPUTS:
- Scene token: {scene_token}
- Frame index: {frame_idx}
- SOURCE OBJECT and DESCRIPTION: {source_object}
- TARGET OBJECT(S) and DESCRIPTION(S): {target_objects}
- SPATIAL CONTEXT BETWEEN SOURCE AND TARGET OBJECT(S): {grounded_context}
- OTHER RELATIONSHIPS: {other_relationships}
- QUESTION GOAL: {question_goal}

NOW GENERATE ONE MCQ:
- Follow the guidelines and use the provided grounded descriptions for the source and target objects.
- Return ONLY the JSON object.